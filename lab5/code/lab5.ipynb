{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-56a7add0-a773-4c3d-953f-0513fe036042",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Lab 5 : 3D reconstruction from N non calibrated cameras. \n",
    "This exercise implements a vanilla version of a Structure from Motion pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00001-0a8d1040-8a9d-4340-ad55-8e2ee470947b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1783,
    "execution_start": 1611948698800,
    "source_hash": "69f1c9a8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-contrib-python==3.4.2.17 in /home/oscar/.local/lib/python3.6/site-packages (3.4.2.17)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/oscar/.local/lib/python3.6/site-packages (from opencv-contrib-python==3.4.2.17) (1.18.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-contrib-python==3.4.2.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00001-637657a4-6a2d-4678-82be-0c8574ebda41",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1016,
    "execution_start": 1611948702528,
    "source_hash": "caef80de",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# opencv, numpy\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# # bundle adjustment\n",
    "import pysba as ba\n",
    "\n",
    "# project files\n",
    "import utils as h\n",
    "import maths as mth\n",
    "import matches as mt\n",
    "import fundamental as fd\n",
    "import track as tk\n",
    "import vps as vp\n",
    "import autocalibration as ac\n",
    "import reconstruction as rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00003-b294a187-070e-4f79-a298-683fba7509d9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1611948705387,
    "source_hash": "9150d61a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with_intrinsics = True\n",
    "n = 2 # number of images to process\n",
    "\n",
    "imgs = []        # list of grayscale images\n",
    "imgs_c = []      # list of colour images\n",
    "feats = []       # list of features\n",
    "matches = []     # list of dictionaries\n",
    "tracks = []      # list of tracking views \n",
    "hs_vs = {}       # dictionary as hash table of views-tracks\n",
    "vps = []         # list of vanishing points \n",
    "cams_pr = []     # list of projective cameras\n",
    "cams_aff = []    # list of affine cameras\n",
    "cams_euc = []    # list of euclidean cameras\n",
    "Xprj = []         # list of projective 3d points\n",
    "Xaff = []        # list of affine 3d points\n",
    "Xeuc = []        # list of euclidean 3d points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00004-77d3bd2d-0de6-4091-87a1-c7c343f025de",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 541,
    "execution_start": 1611948709635,
    "source_hash": "f739b880",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 0 of sequence\n",
      "  Image ../Data/0000_s.png loaded\n",
      "  Colour image ../Data/0000_s.png loaded\n",
      "  Features detected in image  0\n",
      "    Found 2999 features \n",
      "  Vanishing points found\n",
      "  Camera 0 set to identity\n",
      "Processing image 1 of sequence\n",
      "  Image ../Data/0001_s.png loaded\n",
      "  Colour image ../Data/0001_s.png loaded\n",
      "  Features detected in image  1\n",
      "    Found 3000 features \n",
      "  Matching images 0 and 1 for obtaining tracks\n",
      "  Correspondences matched between images 0 and 1\n",
      "    Found 1022 matching correspondences\n",
      "5000 67\n",
      "    Inliers:  1022\n",
      "  Matches corrected with Optimal Triangulation Method\n",
      "  Tracks added after matching 0 and 1\n",
      "    Size of tracks: 1019\n",
      "    Size of hash table of views: 2041\n",
      "  Projective reconstruction estimated\n",
      "  Projective 3D points added to tracks\n",
      "    Projective reprojection error: 5.4961104827573e-09\n",
      "  Vanishing points found\n",
      "  Affine 3D points added to tracks\n",
      "    Affine reprojection error: 5.496107587236846e-09\n",
      "  Euclidean 3D points added to tracks\n",
      "    Euclidean reprojection error: 1153864956.3399506\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, n):\n",
    "    if h.debug >= 0:\n",
    "        print(\"Processing image\", i, \"of sequence\")\n",
    "\n",
    "    # read image\n",
    "    imgs.append(h.read_image(i))\n",
    "    imgs_c.append(h.read_image_colour(i))\n",
    "\n",
    "    # find features\n",
    "    feats.append(mt.find_features_orb(imgs[i], i)) # find_features_sift to use SIFT\n",
    "\n",
    "    if i == 0:\n",
    "        P0 = np.eye(3,4).astype('float32')\n",
    "        cams_pr.append(P0)\n",
    "        vps.append(vp.estimate_vps(imgs[i]))\n",
    "        if h.debug >= 0:\n",
    "            print(\"  Camera 0 set to identity\")\n",
    "    else:\n",
    "        for prev in range(0, i):  \n",
    "            if h.debug >= 0:\n",
    "                print(\"  Matching images\", prev, \"and\", i, \"for obtaining tracks\")\n",
    "            # match features\n",
    "            m_ij = mt.match_features_hamming(feats[prev][1], feats[i][1], prev, i)\n",
    "\n",
    "            # inliers\n",
    "            x1 = []\n",
    "            x2 = []\n",
    "\n",
    "            for m in m_ij:\n",
    "                x1.append([feats[prev][0][m.queryIdx].pt[0], feats[prev][0][m.queryIdx].pt[1], 1])\n",
    "                x2.append([feats[i][0][m.trainIdx].pt[0], feats[i][0][m.trainIdx].pt[1], 1])\n",
    "        \n",
    "            x1 = np.asarray(x1)\n",
    "            x2 = np.asarray(x2)\n",
    "            \n",
    "            # find fundamental matrix\n",
    "            F, inliers = fd.compute_fundamental_robust(m_ij, x1, x2)\n",
    "\n",
    "            if h.debug_display:\n",
    "                img_ij = cv2.drawMatches(imgs[prev],feats[prev][0],\\\n",
    "                    imgs[i],feats[i][0],inliers,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "                plt.imshow(img_ij)\n",
    "                fig = matplotlib.pyplot.gcf()\n",
    "                fig.set_size_inches(18.5, 10.5)\n",
    "                plt.show()\n",
    "\n",
    "            if h.debug > 0:\n",
    "                print(\"    Inliers: \", x1.shape[0])\n",
    "\n",
    "            # refine matches and update the contents of matches\n",
    "            x1 = x1[:, :2]\n",
    "            x2 = x2[:, :2]\n",
    "            xr1, xr2 = fd.refine_matches(x1, x2, F)\n",
    "            tk.add_tracks(x1, x2, xr1.T, xr2.T, prev, i, tracks, hs_vs)\n",
    "            #h.draw_matches_cv(imgs[prev], imgs[i], x1, x2)\n",
    "\n",
    "            if h.debug >= 0:\n",
    "                print(\"  Tracks added after matching\", prev, \"and\", i)\n",
    "            if h.debug > 0:\n",
    "                print(\"    Size of tracks:\", len(tracks))\n",
    "                print(\"    Size of hash table of views:\", len(hs_vs))\n",
    "\n",
    "            if h.debug_display:\n",
    "                h.display_epilines(imgs[prev], imgs[i], x1, x2, F)\n",
    "                h.show_matches(imgs[prev], imgs[i], x1, x2)\n",
    "\n",
    "        # compute projective cameras to use in projective reconstruction\n",
    "        if i == 1:\n",
    "            cams_pr.append(rc.compute_proj_camera(F, i))\n",
    "        else:\n",
    "            # OPTIONAL Compute resection as in MVG, Alg 7.1\n",
    "            cams_pr.append(rc.resection(tracks, i))\n",
    "            if h.debug >= 0:\n",
    "                print(\"  Resection of camera\", i, \"performed\")\n",
    "\n",
    "        # projective triangulation for 3D structure\n",
    "        Xprj = rc.estimate_3d_points_2(cams_pr[i-1], cams_pr[i], xr1, xr2)\n",
    "        if h.debug >= 0:\n",
    "            print('  Projective reconstruction estimated')\n",
    "\n",
    "        # Add estimated 3d projective points to tracks\n",
    "        tk.add_pts_tracks(Xprj, x1, x2, i-1, i, tracks, hs_vs)\n",
    "        if h.debug >= 0:\n",
    "            print('  Projective 3D points added to tracks')\n",
    "\n",
    "        error_prj = rc.compute_reproj_error(Xprj, cams_pr[i-1], cams_pr[i], xr1, xr2)\n",
    "        if h.debug > 0:\n",
    "            print(\"    Projective reprojection error:\", error_prj)\n",
    "\n",
    "        if h.debug_display:\n",
    "            h.display_3d_points(Xprj.T[:, :3], x1, imgs_c[i])\n",
    "        \n",
    "        # Affine rectification\n",
    "        vps.append(vp.estimate_vps(imgs[i]))\n",
    "\n",
    "        # compute affine homography\n",
    "        aff_hom, vp3d = ac.estimate_aff_hom([cams_pr[i-1], cams_pr[i]], [vps[i-1], vps[i]])\n",
    "\n",
    "        # transform 3D points and cameras to affine space\n",
    "        Xaff, cams_aff = rc.transform(aff_hom, Xprj, cams_pr)\n",
    "\n",
    "        # Add estimated 3d affine points to tracks (reuse your code)\n",
    "        tk.add_pts_tracks(Xaff, x1, x2, i-1, i, tracks, hs_vs)\n",
    "        if h.debug >= 0:\n",
    "            print('  Affine 3D points added to tracks')\n",
    "        \n",
    "        # compute affine reprojection error\n",
    "        error_aff = rc.compute_reproj_error(Xaff, cams_aff[i-1], cams_aff[i], xr1, xr2)\n",
    "        if h.debug > 0:\n",
    "            print(\"    Affine reprojection error:\", error_aff)\n",
    "\n",
    "        if h.debug_display:\n",
    "            h.display_3d_points(Xaff.T[:, :3], x1, imgs_c[i])\n",
    "        \n",
    "        ## Metric rectification\n",
    "        ## TODO Perform Metric rectification. First compute the transforming\n",
    "        ## homography from vanishing points and the camera constrains skew = 0,\n",
    "        ## squared pixels. Then perform the transformation to Euclidean space\n",
    "        ## (reuse your code)\n",
    "        if i == 1 and with_intrinsics:\n",
    "            cams_euc = rc.compute_eucl_cam(F, x1, x2)\n",
    "            Xeuc = rc.estimate_3d_points_2(cams_euc[0], cams_euc[1], xr1, xr2)\n",
    "        else: # compare results with the results from intrinsic camera\n",
    "            euc_hom = ac.estimate_euc_hom(cams_aff[i], vps[i])\n",
    "            Xeuc, cams_euc = rc.transform(euc_hom, Xaff, cams_aff)\n",
    "\n",
    "        # TODO Add estimated 3d euclidean points to tracks (reuse your code)\n",
    "        tk.add_pts_tracks(Xeuc, x1, x2, i-1, i, tracks, hs_vs)\n",
    "        if h.debug >= 0:\n",
    "            print('  Euclidean 3D points added to tracks')\n",
    "        \n",
    "        # TODO compute metric reprojection error (reuse your code)\n",
    "        error_euc = rc.compute_reproj_error(Xeuc, cams_euc[i-1], cams_euc[i], xr1, xr2)\n",
    "        if h.debug > 0:\n",
    "            print(\"    Euclidean reprojection error:\", error_euc)\n",
    "\n",
    "        if h.debug_display:\n",
    "            h.display_3d_points(Xeuc.T[:, :3], x1, imgs_c[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00004-3b017fe5-5e09-4b9d-ad94-100398678d94",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0, n):\n",
    "    if h.debug >= 0:\n",
    "        print(\"Processing image\", i, \"of sequence\")\n",
    "\n",
    "    # read image\n",
    "    imgs.append(h.read_image(i))\n",
    "    imgs_c.append(h.read_image_colour(i))\n",
    "\n",
    "    # find features\n",
    "    feats.append(mt.find_features_orb(imgs[i], i)) # find_features_sift to use SIFT\n",
    "\n",
    "    if i == 0:\n",
    "        P0 = np.eye(3,4).astype('float32')\n",
    "        cams_pr.append(P0)\n",
    "        vps.append(vp.estimate_vps(imgs[i]))\n",
    "        if h.debug >= 0:\n",
    "            print(\"  Camera 0 set to identity\")\n",
    "    else:\n",
    "        for prev in range(0, i):  \n",
    "            if h.debug >= 0:\n",
    "                print(\"  Matching images\", prev, \"and\", i, \"for obtaining tracks\")\n",
    "            # match features\n",
    "            m_ij = mt.match_features_hamming(feats[prev][1], feats[i][1], prev, i)\n",
    "\n",
    "            # inliers\n",
    "            x1 = []\n",
    "            x2 = []\n",
    "\n",
    "            for m in m_ij:\n",
    "                x1.append([feats[prev][0][m.queryIdx].pt[0], feats[prev][0][m.queryIdx].pt[1], 1])\n",
    "                x2.append([feats[i][0][m.trainIdx].pt[0], feats[i][0][m.trainIdx].pt[1], 1])\n",
    "        \n",
    "            x1 = np.asarray(x1)\n",
    "            x2 = np.asarray(x2)\n",
    "            \n",
    "            # find fundamental matrix\n",
    "            F, inliers = fd.compute_fundamental_robust(m_ij, x1, x2)\n",
    "\n",
    "            if h.debug_display:\n",
    "                img_ij = cv2.drawMatches(imgs[prev],feats[prev][0],\\\n",
    "                    imgs[i],feats[i][0],inliers,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "                plt.imshow(img_ij)\n",
    "                fig = matplotlib.pyplot.gcf()\n",
    "                fig.set_size_inches(18.5, 10.5)\n",
    "                plt.show()\n",
    "\n",
    "            if h.debug > 0:\n",
    "                print(\"    Inliers: \", x1.shape[0])\n",
    "\n",
    "            # refine matches and update the contents of matches\n",
    "            x1 = x1[:, :2]\n",
    "            x2 = x2[:, :2]\n",
    "            xr1, xr2 = fd.refine_matches(x1, x2, F)\n",
    "            tk.add_tracks(x1, x2, xr1.T, xr2.T, prev, i, tracks, hs_vs)\n",
    "            #h.draw_matches_cv(imgs[prev], imgs[i], x1, x2)\n",
    "\n",
    "            if h.debug >= 0:\n",
    "                print(\"  Tracks added after matching\", prev, \"and\", i)\n",
    "            if h.debug > 0:\n",
    "                print(\"    Size of tracks:\", len(tracks))\n",
    "                print(\"    Size of hash table of views:\", len(hs_vs))\n",
    "\n",
    "            if h.debug_display:\n",
    "                h.display_epilines(imgs[prev], imgs[i], x1, x2, F)\n",
    "                h.show_matches(imgs[prev], imgs[i], x1, x2)\n",
    "\n",
    "        # compute projective cameras to use in projective reconstruction\n",
    "        if i == 1:\n",
    "            cams_pr.append(rc.compute_proj_camera(F, i))\n",
    "        else:\n",
    "            # OPTIONAL Compute resection as in MVG, Alg 7.1\n",
    "            cams_pr.append(rc.resection(tracks, i))\n",
    "            if h.debug >= 0:\n",
    "                print(\"  Resection of camera\", i, \"performed\")\n",
    "\n",
    "        # projective triangulation for 3D structure\n",
    "        Xprj = rc.estimate_3d_points_2(cams_pr[i-1], cams_pr[i], xr1, xr2)\n",
    "        if h.debug >= 0:\n",
    "            print('  Projective reconstruction estimated')\n",
    "\n",
    "        # Add estimated 3d projective points to tracks\n",
    "        tk.add_pts_tracks(Xprj, x1, x2, i-1, i, tracks, hs_vs)\n",
    "        if h.debug >= 0:\n",
    "            print('  Projective 3D points added to tracks')\n",
    "\n",
    "        error_prj = rc.compute_reproj_error(Xprj, cams_pr[i-1], cams_pr[i], xr1, xr2)\n",
    "        if h.debug > 0:\n",
    "            print(\"    Projective reprojection error:\", error_prj)\n",
    "\n",
    "        if h.debug_display:\n",
    "            h.display_3d_points(Xprj.T[:, :3], x1, imgs_c[i])\n",
    "        \n",
    "        # Affine rectification\n",
    "        vps.append(vp.estimate_vps(imgs[i]))\n",
    "        # TODO Estimate homography that makes an affine rectification\n",
    "        # With the vanishing points, the plane at the infinity is computed. \n",
    "        # Then the affine homography is built with the coordinates of the infinity plane\n",
    "        aff_hom = ac.estimate_aff_hom([cams_pr[i-1], cams_pr[i]], [vps[i-1], vps[i]])\n",
    "\n",
    "        # TODO Transform 3D points and cameras to affine space\n",
    "        Xaff, cams_aff = rc.transform(aff_hom, Xprj, cams_pr)\n",
    "\n",
    "        # Add estimated 3d affine points to tracks (reuse your code)\n",
    "        tk.add_pts_tracks(Xaff, x1, x2, i-1, i, tracks, hs_vs)\n",
    "        if h.debug >= 0:\n",
    "            print('  Affine 3D points added to tracks')\n",
    "        \n",
    "        # TODO compute affine reprojection error (reuse your code)\n",
    "        error_aff = rc.compute_reproj_error(Xaff, cams_aff[i-1], cams_aff[i], xr1, xr2)\n",
    "        if h.debug > 0:\n",
    "            print(\"    Affine reprojection error:\", error_aff)\n",
    "\n",
    "        if h.debug_display:\n",
    "            h.display_3d_points(Xaff.T[:, :3], x1, imgs_c[i])\n",
    "\n",
    "        # Metric rectification\n",
    "        # TODO Perform Metric rectification. First compute the transforming\n",
    "        # homography from vanishing points and the camera constrains skew = 0,\n",
    "        # squared pixels. Then perform the transformation to Euclidean space\n",
    "        # (reuse your code)\n",
    "        if i == 1 and with_intrinsics:\n",
    "            cams_euc = rc.compute_eucl_cam(F, x1, x2)\n",
    "            Xeuc = rc.estimate_3d_points_2(cams_euc[0], cams_euc[1], xr1, xr2)\n",
    "        else: # compare results with the results from intrinsic camera\n",
    "            euc_hom = ac.estimate_euc_hom(cams_aff[i], vps[i])\n",
    "            Xeuc, cams_euc = rc.transform(euc_hom, Xaff, cams_aff)\n",
    "\n",
    "        # TODO Add estimated 3d euclidean points to tracks (reuse your code)\n",
    "        tk.add_pts_tracks(Xeuc, x1, x2, i-1, i, tracks, hs_vs)\n",
    "        if h.debug >= 0:\n",
    "            print('  Euclidean 3D points added to tracks')\n",
    "        \n",
    "        # TODO compute metric reprojection error (reuse your code)\n",
    "        error_euc = rc.compute_reproj_error(Xeuc, cams_euc[i-1], cams_euc[i], xr1, xr2)\n",
    "        if h.debug > 0:\n",
    "            print(\"    Euclidean reprojection error:\", error_euc)\n",
    "\n",
    "        if h.debug_display:\n",
    "            h.display_3d_points(Xeuc.T[:, :3], x1, imgs_c[i])\n",
    "\n",
    "        # Bundle Adjustment\n",
    "        # TODO Adapt cameras and 3D points to PySBA format\n",
    "        cams_ba, X_ba, x_ba, cam_idxs, x_idxs = ba.adapt_format_pysba(tracks, cams_euc)\n",
    "\n",
    "        badj = ba.PySBA(cams_ba, X_ba, x_ba, cam_idxs, x_idxs)\n",
    "        cams_ba, Xba = badj.bundleAdjust()\n",
    "        # Update 3D points and tracks with optimised cameras and points\n",
    "        tk.update_ba_pts_tracks(Xba, x1, x2, i-1, i, tracks, hs_vs)\n",
    "        if h.debug >= 0:\n",
    "            print(\"  Bundle Adjustment performed over\", i, \"images\")\n",
    "\n",
    "        # render results\n",
    "        #if h.debug_display:\n",
    "        h.display_3d_points_2(Xba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-e81787aa-cdea-49e1-91cc-95cd7f412ab0",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-bc0a98cb-cd6a-4447-b95e-fe42fe8c00a7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 72,
    "execution_start": 1611939031206,
    "source_hash": "5f46c18b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: python3 lab5.py <number of images to process>\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "text": "Usage: python3 lab5.py <number of images to process>\n/shared-libs/python3.7/py-core/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Optional tasks\n",
    "- Estimate affine homography from the 3 vanishing points and F (Alg. 13.1\n",
    "    p332, result 10.3 p271)\n",
    "- Perform Bundle Adjustment over the estimation of the vanishing points and\n",
    "    all available images, with PySBA\n",
    "\n",
    "For more than 2 images: \n",
    "- Implement the  resection method, as explained in MVG, Alg 7.1\n",
    "- Implement track management for more than 2 images, with tracks structure\n",
    "- Investigate strategies to improve the pipeline:\n",
    "        -in results: number of points, reprojection error, camera poses\n",
    "        -in implementation: time of computation, resources, etc.\n",
    "    Reference papers for improvement strategies: \n",
    "        -J. L. Schönberger and J. Frahm, \"Structure-from-Motion Revisited,\" 2016 IEEE Conference \n",
    "            on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, 2016, pp. 4104-4113.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6c82c801-d9c5-4814-928f-2fae4faac12f",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
